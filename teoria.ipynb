{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1\n",
    "\n",
    "## Introduzione\n",
    "Gli zeri di una funzione sono i punti in cui la funzione si annulla, ovvero i valori di x tali che f(x)=0. Identificarli è un problema comune in matematica, perché spesso rappresentano la soluzione a sistemi complessi.\n",
    "\n",
    "Tuttavia, non tutte le funzioni possono essere risolte analiticamente. Alcune non ammettono una formula chiusa per i loro zeri, e altre sono così complesse da rendere impossibile trovare una soluzione esatta. È qui che entrano in gioco i metodi numerici.\n",
    "\n",
    "### Metodo di bisezione\n",
    "Se una funzione continua cambia segno su un intervallo [a,b], ovvero se f(a)⋅f(b)<0, allora esiste almeno uno zero della funzione in quell'intervallo.\n",
    "\n",
    "Il procedimento è iterativo: dividiamo l’intervallo [a,b] in due parti uguali e calcoliamo il valore della funzione nel punto medio $c=\\frac{a+b}{2}$. Se f(c)=0, abbiamo trovato lo zero. Altrimenti, scegliamo il sottointervallo in cui la funzione cambia segno e ripetiamo il procedimento. Ad ogni iterazione, l’intervallo si restringe, e lo zero viene approssimato con una precisione sempre maggiore.\n",
    "\n",
    "Questo metodo è molto affidabile, ma ha un limite: la sua convergenza è piuttosto lenta rispetto ad altri metodi. Inoltre, richiede che la funzione sia continua e che si conoscano due estremi in cui avviene il cambio di segno.\n",
    "\n",
    "\n",
    "### Metodo delle iterazioni di punto fisso\n",
    "\n",
    "Partendo dall’equazione f(x)=0, possiamo riscriverla come x=g(x). In questo modo, anziché cercare gli zeri di f(x), cerchiamo un punto fisso di g(x), cioè un valore $x^*$ tale che $ g(x^*) = x^*$.\n",
    "\n",
    "Il metodo funziona così: partiamo da un valore iniziale $x_0$ e iteriamo la relazione $x_{n+1}=g(x_n)$. La sequenza ${x_n}$ tende a convergere al punto fisso, che corrisponde allo zero della funzione originale.\n",
    "\n",
    "Questo approccio presenta alcune difficoltà. La convergenza non è garantita in tutti i casi: dipende dalla scelta della funzione g(x) e dal fatto che la derivata $g^′(x)$ sia minore di 1 in valore assoluto nell’intervallo di interesse. Se queste condizioni non sono rispettate, il metodo può divergere.\n",
    "\n",
    "- Vantaggi:\n",
    "    facile da implementare e richiede poche operazioni.\n",
    "    fornisce una rappresentazione diretta della soluzione come punto fisso.\n",
    "\n",
    "    - Svantaggi:\n",
    "    una cattiva stima iniziale può portare a divergenza o a convergenza molto lenta.\n",
    "    converge solo se il punto iniziale $x_0$ è sufficientemente vicino al punto fisso.\n",
    "    la scelta di $g(x)$ non è unica e non tutte le riformulazioni garantiscono la convergenza.\n",
    "\n",
    "### Metodo di Newton\n",
    "La sua idea di base è utilizzare la derivata della funzione per approssimare lo zero. La formula iterativa è: $$x_{n+1} = x_n − \\frac {f(x_n)} {f^′(x_n)}$$\n",
    "Questo metodo si basa sul concetto di linearizzazione: a ogni passo, troviamo il punto in cui la tangente alla curva f(x) nel punto $x_n$ interseca l’asse x. Tale punto di intersezione diventa il nuovo valore di x, e il processo viene ripetuto fino alla convergenza.\n",
    "\n",
    "Il metodo di Newton ha una convergenza quadratica, il che significa che il numero di cifre corrette raddoppia a ogni iterazione, rendendolo estremamente efficiente. Tuttavia, presenta delle criticità:\n",
    "\n",
    "- Richiede il calcolo della derivata della funzione, il che può essere complicato in alcuni casi.\n",
    "- Se la derivata è molto piccola o se il punto iniziale è lontano dallo zero, il metodo può fallire o convergere lentamente.\n",
    "- Inoltre, può convergere a un minimo locale invece che a uno zero, se non si fa attenzione. \n",
    "\n",
    "\n",
    "## funzioni g(x_k+1)\n",
    "## Criteri di arresto (tolleranza e il criterio di come funziona se non conosciamo la soluzione esatta (mi garantisce che va bene perché nel caso il passo è troppo piccolo))\n",
    "\n",
    "## perché g2 non ha convergenza. quali sono le condizioni per cui non converge (il fatto che ci sia una contrazione)\n",
    "Il motivo per cui $g_2(x)$ non converge è che la derivata in modulo è maggiore di 1 vicino allo zero della funzione $f(x)$. Questo implica che le iterazioni tendono ad allontanarsi dalla soluzione invece di avvicinarsi, causando la divergenza del metodo\n",
    "\n",
    "## Cosa significa contrazione? \n",
    "Una funzione è una contrazione se \"stringe\" o \"riduce le distanze\" tra i punti nel suo dominio. Più formalmente, una funzione g(x) definita su un intervallo chiuso [a,b] è detta una mappa contrattiva se esiste una costante C, con $0 < C < 1$, tale che per ogni coppia di punti x,y in [a,b]: $$∣g(x)−g(y)∣≤C∣x−y∣$$\n",
    "La costante C è chiamata costante di contrazione, e il suo valore misura quanto la funzione \"riduce\" le distanze tra i punti. L'importanza di una contrazione sta nel fatto che garantisce la convergenza dell'iterazione di punto fisso. Una contrazione ha esattamente un punto fisso nell'intervallo considerato.\n",
    "\n",
    "## Come si fa a vedere che una funzione ha una contrazione?\n",
    "Se $g:[a,b] \\rightarrow [a,b]$ è una funzione differenziabile su un intervallo chiuso $[a,b]$, e se esiste una costante $C < 1$ tale che: $$|g'(x)| \\le C \\ per \\ ogni \\ x \\in [a,b] $$\n",
    "allora $g(x)$ è una mappa contrattiva. Questo significa che:\n",
    "- $g(x)$ ha esattamente un punto fisso p nell'intervallo $[a,b]$\n",
    "- La successione definita da $x_{k+1} = g(x_k)$, partendo da un punto iniziale $x_0 \\in [a,b]$, converge al punto fisso p\n",
    "\n",
    "Questo teorema si basa sull'osservazione che una contrazione \"stringe\" i punti nel suo dominio, riducendo la distanza tra essi ad ogni iterazione.\n",
    "\n",
    "$|g'(x)| \\le C$, con $C < 1$ garantisce che la funzione non si comporti in modo \"ripido\" o divergente, ma piuttosto che la sua inclinazione rimane limitata. In pratica la derivata controlla la pendenza della funzione: se la pendenza è sempre minore di 1 in valore assoluto, allora la funzione è contrattiva  \n",
    "\n",
    "## Com'è definita la velocità di convergenza? lineare super lineare e quadratica \n",
    "La convergenza $\\mathbf{lineare}$ descrive il modo in cui una successione numerica si avvicina al suo limite ad ogni iterazione. È una misura della velocità di convergenza. Si dice che una successione ${x_k}$ converge linearmente verso un valore p se esiste una costante $C \\in (0,1)$ tale che: $|E_{k+1}| \\le C \\cdot |E_k|$\n",
    "dove C<1 garantisce che l'errore diminuisca per ogni iterazione\n",
    "\n",
    "La convergenza $\\mathbf{superlineare}$ si intende quando l'ordine di convergenza p è compreso tra 1 e 2, quindi si ha la formula: $|E_{k+1}| \\le C \\cdot |E_k|^p$, in cui C è la costante di contrazione e p è l'ordine di convergenza. Questo è il caso del metodo dell'iterazione di punto fisso\n",
    "\n",
    "Nella convergenza $\\mathbf{quadratica}$ invece il nuovo errore è proporzionale al quadrato dell'errore precedente, caratterizzato dalla formula: $|E_{k+1}| \\le C \\cdot |E_k|^p$, in cui p = 2 \n",
    "\n",
    "# 1.2\n",
    "\n",
    "## introduzione e codice\n",
    "I sistemi Ax = b sono risolvibili attraverso i metodi diretti che hanno alta accuratezza ma alta complessità. Dei metodi diretti fanno parte la fattorizzazione LU con pivoting e il metodo di Cholesky. Per quanto riguarda il primo, data una matrice A non singolare e tutti i suoi minori principali diversi da 0, da 1 a n, non singolari, allora esistono le matrici L e U triangolari inferiori e superiori non singolari tali che $A=L \\cdot U$. Non tutte le matrici non singolari possono essere fattorizzate in $L \\cdot U$, infatti pivot molto piccoli potrebbero dare un errore algoritmico molto grande. Per questo si usa la fattorizzazione LU con pivoting. Quindi la soluzione del sistema Ax=y si ottiene risolvendo $$\\begin{cases} Ly = Pb \\\\ Ux = y  \\end{cases}$$\n",
    "\n",
    "Per quanto riguarda il metodo di Cholesky invece si applica alle matrici simmetriche definite positive e propone di risolvere il sistema lineare Ax=b fattorizzando la matrice A in $A=L \\cdot L^T$. Si risolve quindi il sistema formato dalle due equazioni: $$\\begin{cases} Ly = b \\\\ L^T x = y  \\end{cases}$$\n",
    "\n",
    "## Cosa significa fattorizzazione LU? come si scrive la matrice A con LU? e con cholesky?\n",
    "Data una matrice A non singolare e tutti i suoi minori principali di ordine k, da 1 a n, non singolari, allora esistono le matrici L e U triangolari inferiori e superiori non singolari tali che $A=L \\cdot U$.\n",
    "\n",
    "Con fattorizzazione LU:  $\\begin{cases} Ly = Pb \\\\ Rx = y  \\end{cases}$\n",
    "\n",
    "Con Cholesky: $\\begin{cases} Ly = b \\\\ L^T x = y  \\end{cases}$\n",
    "\n",
    "## cos'è il numero di condizione? gli errori da cosa dipendono? (errori inerente) cosa significa errore inerente?\n",
    "Gli errori dipendono dall'errore inerente che è dovuto alla rappresentazione con i numeri finiti, all'errore di rappresentazione. Errore nella rappresentazione dei dati ma le operazioni vengono in aritmetica reale\n",
    "\n",
    "## com'è definito il numero di condizione?\n",
    "Il numero di condizione di una matrice A è una misura della sensibilità della soluzione di un sistema lineare Ax=b rispetto a piccole perturbazioni nei dati. Si definisce formalmente come: $K(A) = || A || \\cdot ||A^{-1}||$. Un numero di condizione piccolo indica che il sistema è ben condizionato, cioè piccole variazioni nei dati producono piccole variazioni nella soluzione e il sistema Ax=b è ben posto \n",
    "\n",
    "## come hai calcolato il numero di condizione?\n",
    "Tramite la funzione np.linalg.cond(A), dove A è la matrice su cui calcolare il numero di condizione\n",
    "\n",
    "# 1.3\n",
    "\n",
    "## introduzione con minimi quadrati\n",
    "Vogliamo risolvere il sistema Ax=b, in cui $A \\in \\mathbb{R}^{mxn}$, $b \\in \\mathbb{R}^{m}$ e $x \\in \\mathbb{R}^{n}$. Il sistema in generale non ha soluzione, dunque cerchiamo di minimizzare il vettore residuo $r=Ax-b$. Il problema lineare dei minimi quadrati è formulato come il minimo del quadrato della norma a 2 del vettore r, ovvero: $min||Ax-b||^2 _2$. \n",
    "Il vettore residuo è pari al rango della matrice A. La matrice delle equazioni normali $A^TA$ è quadrata n*n simmetrica e può essere definita positiva se il vettore residuo r è uguale a n, quindi ha rango massimo e il problema ha un'unica soluzione.\n",
    "Imponendo che il gradiente della funzione obbiettivo $f(x) = ||Ax-b||^2_2$ sia nullo, si ottiene: $\\nabla f(x) = 2A^T(Ax-b) = 0$. Questo porta al sistema delle equazioni normali: $$A^TAx = A^Tb$$\n",
    "$A^TA$ è una matrice simmetrica e definita positiva (se A ha rango massimo), quindi il sistema ammette una soluzione unica. La fattorizzazione di Cholesky, definita come $A^TA = LL^T$ può essere usata per risolvere efficacemente il sistema\n",
    "\n",
    "## equazioni normali\n",
    "\n",
    "## Cosa sono le svd?\n",
    "Data una matrice $A \\in \\mathbb{R}^{mxn}$, la decomposizione in valori singolari costruisce basi ortogonali di $\\mathbb{R}^{m}$ e $\\mathbb{R}^{n}$ che permettono di rappresentare A attraverso una matrice diagonale. Se ha rango k, tale che $k \\le n \\le m $, allora esistono:\n",
    "- una matrice ortogonale $U \\in \\mathbb{R}^{mxn}$\n",
    "- una matrice ortogonale $V \\in \\mathbb{R}^{nxn}$\n",
    "- una matrice diagonale $S \\in \\mathbb{R}^{mxn}$\n",
    "\n",
    "Tali che $A = USV^T$. S è la matrice diagonale composta dai valori singolari di A in senso decrescente. Le colonne di U e V sono rispettivamente i vettori singolari sinistri e detri di A. Quindi il vettore $$x^* = \\sum_{i=1}^{k} \\frac {u_i^T b} {\\sigma _i}v_i$$ è la soluzione di minima norma del problema\n",
    "\n",
    "\n",
    "## La pseudoinversa com'è definita? a cosa serve?\n",
    "Sia $A \\in \\mathbb{R}^{mxn}$, con $rg(A) = k \\le min(m,n)$ e $A = USV^T$ la sua decomposizione in valori singolari. Si definisce pseudoinversa la matrice: $A^+ = VS^+U^T$\n",
    "\n",
    "La pseudoinversa è uno strumento molto utile per analizzare teoricamente il problema dei minimi quadrati e le proprietà delle sue soluzioni, ma non è adeguato per calcolarle poiché computazionalmente costoso\n",
    "\n",
    "## Come si scrive la soluzione dei minimi quadrati una volta calcolata $A^+$?\n",
    "La pseudoinversa di una matrice rettangolare A permette di scrivere la soluzione del problema dei minimi quadrati in modo simile alla soluzione $x=A^{-1}b$ di un sistema lineare quadrato, cioè $$x^* = VS^+U^Tb \\Rightarrow x^* = A^+b$$\n",
    "\n",
    "\n",
    "## Se fosse un sistema lineare quadrato come scriveresti la soluzione? (a cosa è uguale la x in Ax=b)\n",
    "$x = A^{-1}b$, dove $A^{-1}$ è l'inversa della matrice A, $b \\in \\mathbb{R}^{n}$ è il vettore dei termini noti\n",
    "\n",
    "## Cosa sono i residui?\n",
    "Il residuo misura la discrepanza tra il prodotto $Ax_{\\alpha}$ (soluzione approssimata) e b: $r = Ax_{\\alpha} - b$\n",
    "\n",
    "Residuo vs errore relativo:\n",
    "Il residuo misura quanto bene la soluzione approssimata soddisfa l'equazione del sistema lineare.\n",
    "\n",
    "L'errore relativo misura quanto la soluzione approssimata si discosta dalla soluzione esatta.\n",
    "\n",
    "## Cosa signfica ortogonali e ortonormali?\n",
    "Una matrice A è detta ortogonale se le sue colonne (o righe) sono ortogonali tra loro. Questo implica che: $A^TA = D$, dove D è una matrice diagonale (tipicamente l'identità per matrici ortonormali, come spiegato sotto).\n",
    "\n",
    "Una matrice è ortonormale se: \n",
    "- le sue colonne (o righe) sono ortogonali tra loro\n",
    "- ogni colonna ha norma unitaria, cioè: $||v_i|| = \\sqrt {v_i \\cdot v_i} = 1$\n",
    "Questo significa che per una matrice ortonormale A, vale $A^TA=I$\n",
    "\n",
    "# 2.1\n",
    "\n",
    "Per sviluppare un metodo di Approssimazione abbiamo bisogno prima di tutto di un set di dati. Riconosciamo quindi due principali tipi di variabili: \n",
    "- indipendenti (input), che rappresentano un valore noto\n",
    "- dipendenti (output), che rappresentano il valore che vogliamo prevedere\n",
    "\n",
    "Gli algoritmi di approssimazione si basano su due assunzioni principali: i dati seguono l'andamento di una curva relativamente complessa ma con un pattern riconoscibile e i dati non sono disposti in maniera precisa lungo la curva, ma mostrano un comportamento casuale, affetto da rumore\n",
    "\n",
    "Date queste due assunzione, possiamo dire che un metodo di approssimazione è un qualunque algoritmo che, fissato un modello $f_{\\theta}(x)$ dipendente da un'insieme di parametri $\\theta$, calcola il valore dei parametri $\\theta$ tali che $f_{\\theta}(x)$ sia il più possibile vicina a $f(x)$\n",
    "\n",
    "Il modo più naturale per ottenere questi parametri è quello di minimizzare l'errore medio di predizione del modello $f_{\\theta}(x, \\alpha)$ (errore misurato, per motivi statistici, come distanza quadratica) =  $$ \\underset {\\alpha}{\\min} \\sum_{i=1}^{n} (\\alpha ^T x_i ^{(d)} - y_i)^2 $$\n",
    "\n",
    "Definendo la matrice che ha per righe i dati, chiamata matrice di Vandermonde di grado d associata a ${x_1, x_2, ..., x_n}$ la formula sopra è equivalente a: $$\\underset {\\alpha}{\\min} ||X \\alpha - y||^2 _2$$\n",
    "Si può risolvere utilizzando le equazioni normali associate a tale problema, ovvero: $X^TX \\alpha = X^Ty$, che può essere fatto con la decomposizione di Cholesky e la decomposizione in Valori Singolari (SVD).\n",
    "\n",
    "Per quanto riguarda Cholesky. la matrice del sistema deve essere Simmetrica e Definita Positiva (SDP), condizione necessaria e sufficiente per l'applicabilità di questo metodo, se e solo se la matrice X ha rango massimo. Possiamo quindi applicare la decomposizione di Cholesky, che trova una matrice triangolare inferiore L tale che: $X^TX = LL^T$. Il sistema delle equazioni normali può quindi essere risolto tramite il sistema: $$\\begin{cases} Lz = X^Ty \\\\ L^T \\alpha = z \\end{cases}$$\n",
    "\n",
    "Per quanto riguarda la risoluzione tramite SVD, consideriamo la decomposizione in valori singolari: $X = USV^T$, dove $U \\in \\mathbb {R} ^{n \\times n}$ e $V \\in \\mathbb {R}^{(d+1) \\times (d+1)}$ sono matrici ortogonali, mentre $S \\in \\mathbb {R}^{n \\times (d+1)}$ è una matrice diagonale i cui elementi sono i valori singolari della matrice in ordine decrescente. La soluzione esplicita diventa: $$\\alpha = \\sum_{i=1}^{d+1} \\frac {u_i ^T y}{\\sigma _i} v_i$$\n",
    "\n",
    "Notare che le soluzioni di $\\alpha_{chol}$ e $\\alpha_{SVD}$ sono uguali perché soluzioni dello stesso problema ai minimi quadrati\n",
    "\n",
    "\n",
    "Gli iperparametri di un modello di approssimazione sono tutti i parametri del modello che devono essere selezionati a mano dall'utente, in contrapposizione con i parametri, che vengono selezionati automaticamente come soluzione del problema ai minimi quadrati\n",
    "\n",
    "Una scarsa approssimazione, incapace di recuperare l'andamento corretto dei dato è noto come underfit. Se il grado del polinomio è troppo alto, la curva diventa troppo flessibile e inizia a seguire l'andamento oscillatorio del rumore e si comporta non meglio di un grado molto basso (con underfit) in termini di abilità predittiva poiché, avendo imparato il comportamento del rumore non è riuscita a estrarre in maniera efficace il comportamento corretto della curva, noto quindi come overfit.\n",
    "Si può controllare il valore residuo al variare del grado per notare situazioni di underfit/overfit. \n",
    "\n",
    "Per regolarizzazione si fa riferimento a: $$\\underset {\\alpha}{\\min}||X \\alpha - y||_2 ^2 + \\frac {\\lambda}{2}||\\alpha||_2 ^2$$\n",
    "dove il primo termine è il problema ai minimi quadrati, mentre il secondo serve a richiedere che i valori di $\\alpha$ siano il più piccoli possibile, andando quindi a forzare la presenza di vari elementi uguali a 0. Per risolvere questo problema di minimo, osserviamo che il suo gradiente è uguale a 0, quindi se $$(x^TX + \\lambda I)\\alpha = X^Ty$$\n",
    "Da notare che ponendo $\\alpha = 0$ si ottengono le equazioni normali.\n",
    "Può essere risolto con Cholesky o SVD. \n",
    "\n",
    "Nel caso in cui $\\lambda$ sia scelto troppo grande, il termine di regolarizzazione inizia a dominare in maniera esagerata la soluzione, generando quindi una curva che manifesta dei parametri troppo piccoli e che non è in grado di fittare correttamente i dati considerati, portando a underfit.\n",
    "\n",
    "## Metodo dei Gradienti Coniugati \n",
    "Particolarmente efficace quando la matrice A in Ax = y è grande e sparsa (ovvero con tanti elementi nulli). Comunemente utilizzato per risolvere il problema ai minimi quadrati :$\\underset {x \\in \\mathbb{R}^{n}} {\\min} \\frac {1} {2} ||Ax -y||_2 ^2$. Uno dei vantaggi dell'algoritmo applicato ai minimi quadrati è il fatto che, non facendo uso delle equazioni normali, si comporta meglio quando la matrice A è molto mal condizionata. Infatti è noto che: $$k_2(A^TA) = k_2(A)^2$$ e quindi se A è mal condizionata, allora il numero di condizionamento della matrice delle equazioni normali $A^TA$ è molto più grande. Si sceglie un iterato da cui iniziare, un numero di passi iterativi e un criterio di arresto\n",
    "\n",
    "Dato un iterato iniziale a livera scelta (spesso il vettore di zeri) si calcola:\n",
    "- residuo iniziale: $r_0 == A^T(y-Ax_0)$\n",
    "- il vettore direzione iniziale $p_0=r_0$\n",
    "\n",
    "per ogni k=0,1,...,maxit:\n",
    "- calcola il vettore $q_k =Ap_k$\n",
    "- calcola il parametro $\\alpha _k = \\frac {||r_k||_2 ^2} {||q_k||_2 ^2}$\n",
    "- aggiorna la soluzione $x_{k+1} = x_k + \\alpha _k p_k$\n",
    "- aggiorna il residuo $r_{k+1} = r_k - \\alpha _k A^T q_k$\n",
    "- calcola il parametro $\\beta _K = \\frac {||r_{k+1}||_2 ^2} {||r_k||_2 ^2}$\n",
    "- aggiorna la direzione $p_{k+1} = r_k + \\beta _k p_k$\n",
    "\n",
    "Per quanto riguarda il criterio di arresto si basa sul controllare se il residuo $r_k = A^T(y-Ax_k)$ (che è la quantità che si vuole minimizzare) abbia norma minore o uguale ad una tolleranza fissata. In particolare, dato un valore di tol > 0, si interrimpe l'algoritmo per quel valore di k tale che: $$||r_k||_2 \\lt tol \\cdot ||r_0||_2$$\n",
    "\n",
    "Può essere modificato per risolvere problema ai minimi quadrati regolarizzati con Tikhonov: $$min_x \\frac {1} {2} ||Ax-y||_2 ^2 + \\frac {\\lambda} {2} ||Lx||_2 ^2$$ dove L è la matrice di Tikhonov (spesso scelta quella di identità) e $\\lambda \\gt 0$ è il parametro di regolarizzazione. Questo problema ha equazioni normali: $$(A^TA + \\lambda L^TL)x = A^Ty$$ e quindi puo essere risolto con CGLS \n",
    "\n",
    "\n",
    "# 2.2\n",
    "\n",
    "## introduzione, codice\n",
    "Praticamente tutti i problemi reali risolvibili computazionalmente possono essere in qualche modo riformulati come problemi di ottimizzazione, partendo dalla Ricerca Operativa (minimizzazione del percorso sottoposto a vincoli, ...). Tutti questi problemi possono essere riscritti come: $\\underset{x \\in \\Omega}{\\min}f(x)$, dove la funzione $f: \\Omega \\rightarrow \\mathbb{R}$ detta funzione obiettivo, descrive la quantità che si vuole ottimizzare, in funzione di variabili. L'insieme $\\Omega$, spesso detto insieme dei valori accettabili o insieme dei vincoli, descrive sotto quali ipotesi la soluzione x del problema deve sottostare per essere dichiarata accettabile.\n",
    "In base alla forma dell'insieme $\\Omega$ dei vincoli, oltre che alle proprietà matematiche della funzione obiettivo $f(x)$, i problemi di ottimizzazione si classificano in varie categorie:\n",
    "- se $\\Omega = \\mathbb{R}^{n}$, allora diciamo che il problema è uncostrained\n",
    "- se $\\Omega \\subset \\mathbb{R}^{n}$, allora diciamo che il problema è constrained\n",
    "\n",
    "## Scrivere metodo di ricerca in linea in maniera generale\n",
    "Questi algoritmi si basano sulle condizioni del primo ordine (condizione necessaria del primo ordine si riferisce alle proprietà del gradiente della funzione obiettivo in prossimità di punto di minimo) per calcolare soluzioni al problema di ottimizzazione svincolato: $\\underset {x \\in \\mathbb{R}^{n}} {\\min} f(x)$, dove $f(x)$ è la funzione obbiettivo derivabile almeno una volta. L'idea di questo metodo è quello di calcolare il punto di minimo $x^*$ di $f(x)$ attraverso un procedimento iterativo. In particolare, scelto un termine $x_0 \\in \\mathbb{R}^{n}$, si considera l'iterazione: $$x_{k+1} = x_k + \\alpha _k p_k$$\n",
    "dove $\\alpha _k > 0$ è detto step-size, mentre $p_k$ è un vettore detto direzione di discesa e viene scelto in modo tale da assiurare che $f(x_{k+1}) \\le f(x_k)$\n",
    "\n",
    "## Come si puo scegliere alpha?\n",
    "Se il passo è troppo piccolo, gli iterati calcolati dall'algoritmo sono tutti troppo vicini, e non riescono mai a raggiungere il punto di minimo. Se il passo è troppo grande, gli iterati rimbalzano da una parte all'altra della funzione, possibilmente crescendo fino all'infinito. \n",
    "Quindi $\\alpha$ si può scegliere attraverso il teorema che dice: il metodo di Discesa del Gradiente con direzione $p_k = - \\nabla f(x_k)$ converge ad un punto stazionario di $f(x)$ se per ogni $k \\in \\mathbb{N}$, $\\alpha _k$ soddisfa le seguenti condizioni, note come le condizioni di Wolfe: $$\\begin{cases} f(x_k - \\alpha _k \\nabla f(x_k)) \\le f(x_k) - c_1 \\alpha _k ||\\nabla f(x_k)||^2 _2  \\\\ \\nabla f(x_k)^T \\nabla f(x_k - \\alpha _k \\nabla f(x_k)) \\le c_2 ||\\nabla f (x_k)||^2 _2 \\\\ \\end{cases}$$\n",
    "dove $ 0 < c_1 < c_2 < 1$ sono due costanti. La prima condizione, nota come condizione di Armijo, richiede che $f(x_{k+1})$ comporti una decrescita sufficiente di $f(x_k)$. Infatti, siccome $c_1 \\alpha _k ||\\nabla f(x_k)||^2 _2 > 0$, la condizione di Armijo implica che $f(x_{k+1}) \\le f(x_k) - c_1 \\alpha _k || \\nabla f(x_k)||^2 _2 < f(x_k)$\n",
    "\n",
    "## Algoritmo di backtracking\n",
    "Per assicurarsi che le condizioni di Wolfe vengano rispettate si utilizza l'algoritmo di backtracking in cui si inizializza $\\alpha _k$ con una stima di partenza (di solito 1), si controlla se $\\alpha _k$ soddisfa la condizione di Armijo e nel caso l'algoritmo termina. Altrimenti si riduce il valore di $\\alpha _k$ e si ripete dallo step precedente\n",
    "\n",
    "## Criteri di arresto (non maxit, non da garanzie di dove si ferma, non tolleranza) quando gli elementi della successione sono vicini alla convergenza ... ma ce n'è anche un'altra\n",
    "Le condizioni necessarie e sufficienti di ottimalità suggeriscono che un semplice metodo per determinare se un tale valore $x_k$ sia o meno in prossimità di un minimo è controllare il valore di $||\\nabla f(x_k)||_2$. Infatti, se $x_k$ fosse esattamente uguale ad un punto di minimo, allora sarebbe un punto stazionario e quindi varrebbe che $||\\nabla f(x_k)||_2 = 0$. Di conseguenza possiamo immaginare che tanto piu  $||\\nabla f(x_k)||$ è piccola, tanto più $x_k$ sarà vicino ad un punto di minimo. Quindi il primo dei criteri di arresto è: $$||\\nabla f(x_k)||_2 \\le tol f$$\n",
    "\n",
    "Solo questa condizione non è sufficiente, infatti se la funzione $f(x)$ è molto piatta, è possibile che $||\\nabla f(x_k)||_2$ sia piccola, ma $x_k$ lontano dal punto di minimo. Per questo motivo, si è soliti inserire un'ulteriore condizione, definita scegliendo un parametro $tol x$ (attorno a $10^{-6}$) e fermando l'algoritmo quando: $$||x_{k+1} - x_k||_2 \\le tol x$$\n",
    "Quando succede, fermiamo l'algoritmo iterativo e ritorniamo un messaggio di errore che dice che non si è raggiunto il punto di minimo perché la funzione obbiettivo era troppo piatta\n",
    "\n",
    "## Che caratteristica ha f1? Convessa, quindi minimo globale\n",
    "Una funzione è convessa se, presi due punti distinti x e y, allora il segmento che congiunge f(x) con f(y) sta sempre sopra alla curva di grafico definita tra x e y\n",
    "\n",
    "## Metodo di Discesa del Gradiente\n",
    "Un vettore $p_k \\in \\mathbb{R}$ è una direzione di discesa per $f(x)$ in $x_k$ se: $$p_k ^T \\nabla f(x_k) \\le 0$$\n",
    "Scegliendo come direzione di discesa la direzione dell'antigradiente, si ottiene un metodo di ricerca in linea per l'ottimizzazione della funzione $f(x)$, definito da: $$\\begin {cases} x_0 \\in \\mathbb{R}^n \\\\ x_{k+1} = x_k - \\alpha _k \\nabla f(x_k) \\end {cases}$$\n",
    "\n",
    "Si osservi che il gradiente di una qualunque funzione rappresenta il vettore che, applicato ad x, punta nella direzione di massima crescita. Quindi ha intuitivamente senso che il vettore a lui opposto punti verso una direzione verso cui la funzione decresce. Per questo è chiamato metodo di ripida discesa \n",
    "\n",
    "## Caratterizzazione delle funzioni convesse\n",
    "Quando la funzione $f(x)$ è sufficientemente liscia, è possibile distinguere funzioni convesse da funzioni non convesse semplicemente calcolandone l’Hessiana (ovvero, la generalizzazione in dimensione $n$ del concetto di derivata seconda).\n",
    "\n",
    "L’importanza delle funzioni convesse nell’ottimizzazione, risiede nella seguente proprietà:\n",
    "- Sia $f: \\mathbb {R}^n \\rightarrow \\mathbb {R}$ una funzione convessa. Se $x^*$ è un punto di minimo locale per $f$, allora $x^*$ è un punto di minimo globale per $f$. Il quale, unitamente al fatto che funzioni convesse definite su $\\mathbb{R}^n$ che non siano costanti non hanno alcun punto di massimo, ci assicura che qualunque estremante di una funzione convessa, è necessariamente, un punto di minimo globale.\n",
    "\n",
    "Un'ipotesi spesso adottata in ottimizzazione è che la funzione obiettivo, oltre ad essere convessa sia anche coerciva, ovvero che: $$\\underset {||x|| \\rightarrow \\infty}{\\lim} f(x)= + \\infty$$\n",
    "Questa ipotesi ci assicura che $f(x)$ abbia almeno un punto di minimo che, per via della convessità, è necessariamente un punto di minimo (globale)\n",
    "\n",
    "# 3.1\n",
    "\n",
    "## introduzione e codice\n",
    "Consideriamo problemi inversi lineari rappresentati da un modello lineare $Ax = y$ dove A è la matrice che rappresenta il sistema di acquisizione, $x$ è la causa (ossia l'oggetto acquisito) e y sono i dati. Il problema inverso consiste nel determinare x conoscendo A e y.\n",
    "\n",
    "Nelle applicazioni reali i dati y sono sempre affetti da rumore e il problema diventa quindi: $Ax = y + \\delta = y^{\\delta}$\n",
    "\n",
    "Nel caso in cui la matrice A è mal condizionata (quindi problema mal posto), il problema viene risolto come un problema di minimi quadrati: $$min_x ||Ax-y^{\\delta}||_2 ^2$$\n",
    "La soluzione del problema dei minimi quadrati ottenuta utilizzando la SVD è: $$x^* = \\sum _{i=1} ^n \\frac {u_i ^T y^{\\delta}} {\\sigma _i} v_i$$\n",
    "\n",
    "In presenza di errore $\\delta$ sui dati, a causa del mal condizionamento della matrice A, la soluzione del problema dei minimi quadrati è dominata dal rumore e risulta molto diversa dalla \"soluzione vera\"\n",
    "\n",
    "## che dimensione ha A\n",
    "$A \\in \\mathbb{R} ^{m \\times n}$, con $m \\ge n$\n",
    "\n",
    "## cosa sono le condizioni discrete di picard?\n",
    "Si tratta di visualizzare contemporaneamente i valori singolari $\\sigma _i$, i valori $u_i ^T y^{\\delta}$ (detti coefficienti di Fourier) e i coefficienti della soluzione $\\frac {u_i ^T y^{\\delta}} {\\sigma _i}$\n",
    "\n",
    "La condizione discreta di Picard è soddisfatta quando i coefficienti di Fourier decrescono più velocemente dei valori singolari (indipendentemente dal loro valore). Quando la condizione discreta di Picard non è soddisfatta i coefficienti della soluzione cominciano a crescere e nella seconda somma (quella che coinvolge il vettore $e$ del rumore) amplificano il valore di $\\delta$\n",
    "\n",
    "Inoltre è importante vedere il comportamento dei vettori singolari $v_i$. Al crescere dell'indice aumentano anche le oscillazioni nei vettori $v_i$. Quindi i vettori singolari moltiplicati per i coefficienti piu’ grandi sono quelli che hanno oscillazioni di ampiezza maggiore. Queste oscillazioni vengono ulteriormente amplificate nelle soluzione dalla moltiplicazione per i coefficenti $\\frac {u_i ^T \\delta} {\\sigma _i}$\n",
    "\n",
    "Questo comportamento non deriva dall'algoritmo usato ma dai dati del problema, cioè dalla malposizione della matrice A e per cercare di risolvere questo problema devo modificare il problema che risolvo, tramite metodi di regolarizzazione come TSVD\n",
    "\n",
    "## TVSD\n",
    "Nel metodo di regolarizzazione TSVD (Decomposizione in Valori Singolari Troncata), la soluzione del problema di minimi quadrati: $min_x ||Ax - y^{\\delta}||_2 ^2$ viene approssimata come: $$x_{TSVD} = \\sum _{i=1} ^{K} \\frac {u_i ^T y^{\\delta}} {\\sigma _i} v_i$$\n",
    "con $K \\lt n$. Si può scrivere la soluzione anche come: $$x_{TSVD} = \\sum _{i=1} ^n f_i \\frac {u_i ^T y^{\\delta}} {\\sigma _i} v_i$$ dove i coefficienti $f_i$ sono detti fattori di filtro, dati da \n",
    "\n",
    "$f_i = 1, i \\le K$\n",
    "\n",
    "$f_i = 0, i \\gt K$\n",
    "\n",
    "## Tikhonov\n",
    "\n",
    "Una alternativa più efficiente è quella di utilizzare fattori di filtro che siano numeri in [0,1] e che quindi pesino le componenti della somma in modo graduale. In particolare, devono essere pesate di più le componenti di indice piccolo, associate ai valori singolari più grandi, e meno quelle di indice grande, associate ai valori singolari più piccoli.\n",
    "Il problema diventa quindi: $$x_{tikh} = min_x ||Ax -y^{\\delta}||_2 ^2 + \\lambda ||Lx||_2 ^2$$ dove $\\lambda \\gt 0$ è il parametro di regolarizzazione che pesa la parte di congruenza con i dati e la parte di regolarità della soluzione, L è la matrice identità oppure una matrice che deriva dalla discretizzazione delle derivate prime o seconde\n",
    "\n",
    "## com'è stato scelto il lambda?\n",
    "Un parametro troppo piccolo non toglie il rumore dalla soluzione, mentre un parametro troppo grande produce una soluzione troppo regolare, in cui non e’ piu’ presente il rumore ma per esempio le oscillazioni o i picchi che ci sono nella soluzione esatta vengono troppo ridotti. Teoricamente il valore ottimale del parametro $\\lambda _{opt}$ è quello che minimizza: $$\\lambda _{opt} = min _\\lambda ||x _\\lambda - x_{GT}||_2 ^2$$ dove $x_\\lambda$ è la soluzione calcolata in corrispondenza di un certo $\\lambda$ e $x_{GT}$ è la soluzione esatta\n",
    "\n",
    "La tecnica più usata è il principio di massima discrepanza in cui, supponendo di avere informazioni sul rumore, in particolare di conoscere la norma del rumore $||\\delta ||_2$ possiamo applicare il principio di massima discrepanza. Il lambda tramite DP deve soddisfare la seguente relazione: $$||Ax_{tik} - y^{\\delta}||_2 ^2 = v$$\n",
    "Poiché il residuo varia con continuità e in modo monotono la soluzione esiste ed è unica. La definizione ci dice che la norma del residuo deve essere uguale alla discrepanza sui dati. Il valore v viene scelto di solito come un valore di poco superiore a 1 (1.01, 1.001)\n",
    "\n",
    "Le oscillazioni nella soluzione sono date dalla seconda sommatoria: $$\\sum _{i=1} ^n \\frac {u_i ^T y} {\\sigma _i} v_i + \\sum _{i=1} ^n \\frac {u_i ^T \\delta} {\\sigma _i} v_i$$\n",
    "\n",
    "# 3.2\n",
    "L'acquisizione delle immagini digitali è un processo che converte un segnale analogico in una rappresentazione numerica, tipicamente una matrice di pixel, ciascuno dei quali rappresenta un valore d’intensità luminosa. Tuttavia, questo processo è soggetto a degrado a causa di fenomeni quali la sfocatura e l’introduzione di rumore. Il problema può essere formalizzato matematicamente come: $y^{\\delta} = A(x) + w$ dove A(x) rappresenta l'operatore di acquisizione dell'immagine, solitamente modellato come una convoluzione con la PSF; w è il rumore additivo e $y^{\\delta}$ è l'immagine acquisita, che risulta degradata rispetto all'originale. L'obbiettivo del problema inverso è stimare x a partire da y e A. Tuttavia il problema è tipicamente mal posto, e si utilizzano metodi di regolarizzazione per stabilizzare la soluzione, come Tikhonov\n",
    "\n",
    "## Tikhonov\n",
    "Va applicata una regolarizzazione: $$min_x f(x) = min _x ||Ax-y^{\\delta}||_2 ^2 + \\lambda ||x||_2 ^2$$ dove $\\lambda$ è il parametro di regolarizzazione. Applicando le condizioni del primo ordine $\\nabla (f) = 0$ si ottiene: $(A^TA + \\lambda I)x = A^Ty^{\\delta}$. Questo sistema lineare ha matrice simmetrica e definita positiva quindi posso risolverlo applicando il metodo CGLS. \n",
    "\n",
    "$\\lambda$ si può scegliere tramite un modo euristico o il DP. Per verificare sperimentalmente il parametro ottimale nel caso in cui si abbia la soluzione esatta è quello di verificare quale parametro rispetto a quelli scelti produce l'errore minore rispetto alla ground truth.\n",
    "\n",
    "## Total Variation\n",
    "Una funzione di regolarizzazione alternativa a quella di Tikhonov è la Variazione Totale (TV).\n",
    "La funzione TV non è differenziabile nel punto (0,0). Per ottenre la differenziabilità si aggiunge un piccolo parametro $\\beta \\gt 0$ (spesso valori nell'ordine di $10^{-3}$): $$ TV ^{\\beta} (x) = \\sum _{i=1} ^{m} \\sum _{j=1} ^{n} \\sqrt {(x_{i+1,j} - x_{i,j})^2 + (x_{i,j+1} - x_{i,j})^2 + \\beta ^2}$$ \n",
    "\n",
    "Il problema di regolarizzazione diventa quindi: $$min _x ||Ax - y ^{\\delta}||_2 ^2 + \\lambda TV ^{\\beta}(x)$$\n",
    "dove il termine di variazione totale penalizza le variazioni graduali mantenendo però le discontinuità nette. Questo approccio è particolarmente efficace per migliorare la qualità delle immagini rimuovendo il rumore senza sfumare i bordi degli oggetti. Per la risoluzione di questo problema di minimo di una funzione convessa può essere risolto con il metodo di discesa del gradiente, utilizzando l'algoritmo di backtracking per la scelta del passo per garantire la convergenza al punto di minimo.\n",
    "\n",
    "\n",
    "La soluzione naive è quella ottenuta risolvendo il problema ai minimi quadrati: $min_x || Ax - y ^{\\delta}|| _2 ^2$. Non posso usare la SVD perché A è di grandi dimensioni ed è troppo costosa computazionalmente. Allora risolvo con le equazioni normali in cui il sistema ha matrice simmetrica e definita positva: $A^TAx = A^Ty^{\\delta}$. Per ragioni computazionali è conveniente applicare il metodo CGLS al sistema delle equazioni normali.\n",
    "\n",
    "Le metriche di valutazione comprendono:\n",
    "- l'errore relativo: $ER = \\frac {|| x-x_{GT}||_2 ^2} {||x_{GT}||_2 ^2}$\n",
    "- il rapporto segnale-rumore misurato come Peak to Signal Noise Ratio (PSNR): $PSNR = 10 \\log _{10} \\frac {(max _{i,j}|x_{i,j}|)^2} {MSE}$ dove MSE indica l'errore quadratico medio, corrispondente a: $MSE= \\frac {||x-x_{GT}||_2 ^2}{M*N}$\n",
    "- SSIM: ha valori in [0,1] e più è alto, più è alta la qualità dell'immagine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolazione\n",
    "Dati $n+1$ punti distinti $(x_0, y_0),(x_1, y_1), ..., (x_n, y_n)$, con $x_0 \\lt x_1 \\lt ... \\lt x_n$ chiamati nodi, il problema di interpolazione consiste nel trovare una funzione polinomiale $p(x)$, chiamata interpolante, tale che $p(x_k) = y_k$ per $k=0,...,n$\n",
    "\n",
    "I coefficienti del polinomio di interpolazione di $n+1$ punti $(x_i, y_i) = (x_i, f(x_i))$ si potrebbero calcolare risolvendo il sistema lineare: $$c_0 + c_1 x_1 + ... + c_n x_1 ^n = y_1$$ $$c_0 + c_1 x_2 + ... + c_n x_2 ^n = y_2$$\n",
    "La matrice dei coefficienti di questo sistema, detta matrice di Vandermonde, può essere molto mal condizionata, quindi si una un approccio differente.\n",
    "\n",
    "Definisco particolari polinomi di grado n: $\\phi _k(x_j) = \\delta _{k,j}$, dove $\\phi _k = 0$ se $k \\ne j$ e $\\delta _{k,j} = 1$ se $k=j$\n",
    "\n",
    "Le funzioni $\\phi _k$ possono essere riscritte come: $$\\phi _k(x) = \\prod_{j=0 j \\ne k}^n \\frac {x - x_j}{x_k - x_j}$$\n",
    "Quindi posso semplicemente scrivere il polinomio di interpolazione come (forma di Lagrange): $$p_n (x) = y_0 \\phi _0 (x) + y_1 \\phi _1 (x) + ... y_n \\phi _n (x) = \\prod _{k=0} ^{n} y_k \\phi _k (x)$$\n",
    "Infatti soddisfa le condizioni di interpolazione: $$p_n (x_i) = \\sum _{k=0} ^n y_k \\phi _k (x_i) = \\sum _{k=0} ^{n} y_k \\delta _{i,k} = y_i$$\n",
    "\n",
    "Sia I un intervallo limitato, e si considerino $n+1$ nodi di interpolazione distinti $x_i$, $i=0,...,n$. Sia f derivabile con continuità fino all'ordine $n+1$ in I. Allora $\\forall x \\in I \\exists \\eta \\in I$ tale che: $$E (x) = f(x) - p_n (x) = \\frac {f^{n+1}(\\eta)} {n+1!} \\prod _{i=0} ^n (x-x_i)$$\n",
    "Da questo teorema non riusciamo a dedurre che, qualsiasi sia la distribuzione dei nodi, $max_{x \\in I} |E(x)| \\rightarrow 0$ per $n \\rightarrow \\infty$. Esistono anche funzioni, come la funzione di Runge, in cui per determinare scelte dei nodi, per esempio equidistanti, $max_ {x \\in I} |E(x)| \\rightarrow \\infty$ per $n \\rightarrow \\infty$\n",
    "\n",
    "Questo risultato indica che ad un aumento del grado n del polinomio interpolatore non corrisponde necessariamente un miglioramento nella ricostruzione di una funzione f\n",
    "\n",
    "## LASSO\n",
    "Si possono utilizzare algoritmi che migliorano le prestazioni del metodo di regolarizzazione. La principale linea di ricerca si concentra sul determinare differenti funzioni di regolarizzazione alternative al termine di Tikhonov. Quella più usata è il metodo LASSO, la cui formula è: $$\\underset {\\alpha}{\\min} ||X \\alpha - y||_2 ^2 + \\lambda ||\\alpha ||_1$$\n",
    "L'idea è quella di visualizzare la forma delle curve di livello della norma 1 rispetto alla norma 2 e si nota subito come il punto di intersezione di una retta casuale tangente a tali curve ha una probabilità molto più ampi di stare su uno degli assi del piano cartesiano. Questo porta che la norma 1 favorisce delle soluzioni $\\alpha$ contenente un numero maggiore di elementi uguali a 0, che è quello che vorremmo ottenere con la regolarizzazione. Il problema di questo metodo risiede nel fatto che la risoluzione del problema non è associata ad alcun tipo di equazioni normali (a causa della norma 1) e quindi richiede di sviluppare algoritmi più avanzati\n",
    "\n",
    "\n",
    "## Definizioni\n",
    "Definizione di matrice estesa:\n",
    "\n",
    "Sia A una matrice di dimensioni $M \\times N$ e sia $k \\in \\mathbb{N}$, diciamo che: una matrice B di dimensioni $(M + 2k) \\times (N + 2k)$ estende la matrice A se e solo se vale: $$\\forall (i,j) \\in \\{ 1, ..., M \\} \\times \\{ 1, ..., N \\}$$\n",
    "\n",
    "Definizione di centro di una matrice:\n",
    "\n",
    "Sia K una matrice di dimensioni $D \\times  D$, con D dispari. Definiamo il centro della matrice K come l'elemento delle coordinate $( \\frac {D+1} {2}, \\frac {D+1} {2})$\n",
    "\n",
    "Definizione di convoluzione di K e A rispetto all'estensione B:\n",
    "Sia A una matrice di dimensioni $M \\times N$ e K una matrice di dimensioni $D \\times D$, con D un numero naturale dispari. Sia B una matrice di dimensioni $(M + (D - 1)) \\times (N + (D-1))$ che estenda A. Definiamo la matrice C di dimensioni $N \\times N$: $$C_{i,j} = \\sum _{m=1} ^{(D-1) /2} \\sum _{n=1} ^{(D-1) /2} K(m,n)W_{i,j}(m,n)$$ questa matrice C, che verrà anche denotata con $C= [K * A | B ]$, è chiamata convoluzione di K e A rispetto all'estensione B. La matrice K prende il nome di nucleo di convoluzione o kernel di convoluzione\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
